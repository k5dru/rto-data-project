{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e99444",
   "metadata": {},
   "source": [
    "# goal:  fetch the minimal set of data from SPP sources for the current interval or a past interval\n",
    "# persist in a database (try postgresql)\n",
    "\n",
    "\n",
    " ## TODO\n",
    " - DONE: figure out if we are ON or OFF the renaming of columns bandwagon.  We are ON the rename bandwagon for now, but a change to standardize_columns would change that.\n",
    "     Background: https://dba.stackexchange.com/questions/250943/should-i-not-use-camelcase-in-my-column-names\n",
    " \n",
    " - REFACTOR to get the most recent available RTBM file, and use that as a time basis. \n",
    "     * Combine as much as possible in a common function \n",
    "     * Backfill: Provide the ability to query recent intervals that are not in the database, create a valid path from interval timestamps (stlf appears tricky), and slowly backfill a day of data\n",
    "     * Optional Forward fill: for Multi-Day Resource Assessment, provide a way to forward-fill for a few days\n",
    " - CLEAN UP so that when exported to a python file it just runs without edits, and produces sane reports from each module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c00ab",
   "metadata": {},
   "source": [
    "### Prerequisite:  \n",
    "* miniconda installation from 2023 or later \n",
    "* in anaconda powershell prompt, \"conda activate 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8106e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install duckdb\n",
    "import pandas as pd \n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc299e87",
   "metadata": {},
   "source": [
    "Source data model is in https://docs.google.com/spreadsheets/d/1Qh28Lb4dcbw9YMqcXLSj7N8l6Tlr46xNQkV-t1A2txc/edit#gid=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c814d8",
   "metadata": {},
   "source": [
    "## Define local database. Duckdb is cool and all, but how about a real database? \n",
    "\n",
    "  \n",
    "    \n",
    "    to initiate session:\n",
    "    SET default_tablespace = u02_pgdata;\n",
    "    create schema if not exists sppdata authorization current_user;\n",
    "    set search_path to sppdata;\n",
    "    \n",
    "    to drop everything: \n",
    "     select 'drop table ' || table_name || ' cascade;' from information_schema.tables where table_schema = 'sppdata';\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c947470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# read the database information from the json file\n",
    "with open('../dbconn.json', 'r') as f:\n",
    "    di = json.load(f)\n",
    "# create a connection string for postgresql\n",
    "pg_uri = f\"//{di['username']}:{di['password']}@{di['host']}:{di['port']}/{di['database']}\"    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ef8419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: fe_sendauth: no password supplied\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3269\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3248\u001b[0m \u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3249\u001b[0m \n\u001b[0;32m   3250\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3267\u001b[0m \n\u001b[0;32m   3268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:455\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:1270\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1270\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:719\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 719\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:396\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:681\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 681\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:905\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 905\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    906\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\create.py:640\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\default.py:580\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOperationalError\u001b[0m: connection to server at \"localhost\" (::1), port 5432 failed: fe_sendauth: no password supplied\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m alchemyEngine   \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostgresql+psycopg2://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpg_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, pool_recycle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3600\u001b[39m);\n\u001b[0;32m     15\u001b[0m  \u001b[38;5;66;03m# Connect to PostgreSQL server\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m con    \u001b[38;5;241m=\u001b[39m \u001b[43malchemyEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# con.execute (text(\"SET default_tablespace = u02_pgdata\"))\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# con.execute (text(\"create schema if not exists sppdata authorization current_user\"))\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# con.execute (text(\"set search_path to sppdata\"))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m con\u001b[38;5;241m.\u001b[39mautocommit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m;\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3245\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[0;32m   3223\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3224\u001b[0m \n\u001b[0;32m   3225\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3242\u001b[0m \n\u001b[0;32m   3243\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 147\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2410\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect)\u001b[0m\n\u001b[0;32m   2408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2412\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    148\u001b[0m             err, dialect, engine\n\u001b[0;32m    149\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3269\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m   3248\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3249\u001b[0m \n\u001b[0;32m   3250\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3267\u001b[0m \n\u001b[0;32m   3268\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:455\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:1270\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1270\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1273\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:719\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    717\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 719\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    722\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:396\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:681\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 681\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:905\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 905\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    906\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\pool\\base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\create.py:640\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\sqlalchemy\\engine\\default.py:580\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\2023\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: fe_sendauth: no password supplied\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "#!pip install sqlalchemy\n",
    "#!pip install psycopg2\n",
    "\n",
    "# using https://pythontic.com/pandas/serialization/postgresql as example\n",
    "# though https://naysan.ca/2020/05/31/postgresql-to-pandas/ avoids the sqlalchemy layer\n",
    "# Example python program to read data from a PostgreSQL table\n",
    "# and load into a pandas DataFrame\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Create an engine instance\n",
    "alchemyEngine   = create_engine(f'postgresql+psycopg2://{pg_uri}', pool_recycle=3600);\n",
    "\n",
    " # Connect to PostgreSQL server\n",
    "con    = alchemyEngine.connect();\n",
    "# con.execute (text(\"SET default_tablespace = u02_pgdata\"))\n",
    "# con.execute (text(\"create schema if not exists sppdata authorization current_user\"))\n",
    "# con.execute (text(\"set search_path to sppdata\"))\n",
    "\n",
    "con.autocommit=False;\n",
    "# Read data from PostgreSQL database table and load into a DataFrame instance\n",
    "#dataFrame       = pd.read_sql(text(\"select * from information_schema.tables\"), con);\n",
    "#dataFrame\n",
    " \n",
    "\n",
    "def pgsqldf(query): \n",
    "    return pd.read_sql(text(query), con)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3643cc8",
   "metadata": {},
   "source": [
    "### example dataframe to table \n",
    "\n",
    "    dataFrame.to_sql(\"test_table\", con=con, if_exists='replace', index=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9d0f6",
   "metadata": {},
   "source": [
    "### example table to dataframe: \n",
    "    df=pd.read_sql(text(\"select * from information_schema.tables\"), con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c74c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit();  #  OH YEAH!  I'm on a real database!  changes need to be committed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb0080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if wanting to nuke the world and start over: \n",
    "if False: \n",
    "    for table_name in ['rtbm_lmp_by_location', \n",
    "        'da_lmp_by_location', \n",
    "        'area_control_error', \n",
    "        'stlf_vs_actual', \n",
    "        'mtlf_vs_actual', \n",
    "        'tie_flows_long', \n",
    "        'rtbm_binding_constraints',\n",
    "        'generation_mix',\n",
    "        'settlement_location',\n",
    "    ]: \n",
    "        con.execute(text(f\"drop table {table_name} cascade\"))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e302cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to transform source data column names to a more appropriate form for working with data:\n",
    "def standardize_columns(df): \n",
    "    df.columns = (df.columns\n",
    "                    .str.replace('^ ', '', regex=True)\n",
    "                    .str.replace('(?<=[a-z])(?=[A-Z])', '_', regex=True)\n",
    "                    .str.replace('[_ ]+', '_', regex=True)\n",
    "                    .str.lower()\n",
    "                 )    \n",
    "    \n",
    "    # add an inserted time to all dataframes\n",
    "    if not 'inserted_time' in df.columns.values: \n",
    "        df['inserted_time'] = datetime.now(pytz.timezone(\"America/Chicago\"))\n",
    "\n",
    "     \n",
    "    print(\"standardized columns: \",  df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be0ee5",
   "metadata": {},
   "source": [
    "# Settlement Locations\n",
    "and their estimated locations, from a local project file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a39d416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized columns:  ['settlement_location' 'inferred_location_type' 'est_latitude'\n",
      " 'est_longitude' 'inserted_time']\n",
      "Index(['settlement_location', 'inferred_location_type', 'est_latitude',\n",
      "       'est_longitude', 'inserted_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if False: \n",
    "    # todo:  store the notebook that created this file and this file in documentation somewhere\n",
    "    df=pd.read_csv(\"c:/Users/Operator/Downloads/UALR_MastersProject/SPPLocation/settlement_node_location.csv\")\n",
    "\n",
    "    \"\"\"\":# for database operations, rename all table and field names to lowercase snake_case\n",
    "    df.rename(columns={'Settlement Location':'settlement_location',\n",
    "               'InferredLocationType':'inferred_location_type',\n",
    "               'est_Latitude':'est_latitude',\n",
    "               'est_Longitude':'est_longitude'}, inplace=True)\n",
    "    \"\"\"\n",
    "\n",
    "    standardize_columns(df)\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45286753",
   "metadata": {},
   "source": [
    "    # per https://duckdb.org/docs/guides/python/import_pandas.html, duckdb just knows about dataframes; no import necessary\n",
    "    # create the table \"my_table\" from the DataFrame \"my_df\"\n",
    "    duckdb.sql(\"CREATE or replace TABLE settlement_location AS SELECT * FROM df\")\n",
    "    # or\n",
    "    # insert into the table \"my_table\" from the DataFrame \"my_df\"\n",
    "    # duckdb.sql(\"INSERT INTO my_table SELECT * FROM my_df\")\n",
    "\n",
    "    # check that it got there\n",
    "    duckdb.sql(\"SELECT table_catalog, table_name, column_name, is_nullable, data_type from information_schema.columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c18a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    # this only needs to be done when settlement locations table changes, and now views depend on it.\n",
    "\n",
    "    df.to_sql(\"settlement_location\", con=con, if_exists='replace', index=False); \n",
    "\n",
    "    con.execute(text(\"\"\"alter table settlement_location \n",
    "    add constraint settlement_location_pk \n",
    "    primary key (settlement_location)\"\"\"\n",
    "                    )\n",
    "               )\n",
    "\n",
    "    con.commit()  #  OH YEAH!  I'm on a real database!  changes need to be committed.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a986a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>settlement_location</th>\n",
       "      <th>inferred_location_type</th>\n",
       "      <th>est_latitude</th>\n",
       "      <th>est_longitude</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSPWR</td>\n",
       "      <td>Resource</td>\n",
       "      <td>35.244014</td>\n",
       "      <td>-102.683243</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WAUE.NWPS.BEETHOVEN</td>\n",
       "      <td>Resource</td>\n",
       "      <td>43.185846</td>\n",
       "      <td>-98.075775</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPS.ENGCARBON1</td>\n",
       "      <td>Resource</td>\n",
       "      <td>35.691881</td>\n",
       "      <td>-101.407891</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NPPD_HAST_WEC1</td>\n",
       "      <td>Resource</td>\n",
       "      <td>40.584211</td>\n",
       "      <td>-98.302139</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDE_MWW</td>\n",
       "      <td>Resource</td>\n",
       "      <td>38.602881</td>\n",
       "      <td>-95.906138</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WR.WOLF</td>\n",
       "      <td>Resource</td>\n",
       "      <td>38.251850</td>\n",
       "      <td>-95.715891</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WR_FLATRIDGESOUTH</td>\n",
       "      <td>Resource</td>\n",
       "      <td>37.373234</td>\n",
       "      <td>-98.250795</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SECI.RUBART.RT04</td>\n",
       "      <td>Resource</td>\n",
       "      <td>37.556793</td>\n",
       "      <td>-101.066421</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OMPA_LAMB_1</td>\n",
       "      <td>Resource</td>\n",
       "      <td>36.807890</td>\n",
       "      <td>-97.112764</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WR_KP_CCPUCIC1</td>\n",
       "      <td>Resource</td>\n",
       "      <td>38.543348</td>\n",
       "      <td>-96.139474</td>\n",
       "      <td>2023-03-02 19:14:47.084471+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   settlement_location inferred_location_type  est_latitude  est_longitude  \\\n",
       "0                GSPWR               Resource     35.244014    -102.683243   \n",
       "1  WAUE.NWPS.BEETHOVEN               Resource     43.185846     -98.075775   \n",
       "2       SPS.ENGCARBON1               Resource     35.691881    -101.407891   \n",
       "3       NPPD_HAST_WEC1               Resource     40.584211     -98.302139   \n",
       "4              EDE_MWW               Resource     38.602881     -95.906138   \n",
       "5              WR.WOLF               Resource     38.251850     -95.715891   \n",
       "6    WR_FLATRIDGESOUTH               Resource     37.373234     -98.250795   \n",
       "7     SECI.RUBART.RT04               Resource     37.556793    -101.066421   \n",
       "8          OMPA_LAMB_1               Resource     36.807890     -97.112764   \n",
       "9       WR_KP_CCPUCIC1               Resource     38.543348     -96.139474   \n",
       "\n",
       "                     inserted_time  \n",
       "0 2023-03-02 19:14:47.084471+00:00  \n",
       "1 2023-03-02 19:14:47.084471+00:00  \n",
       "2 2023-03-02 19:14:47.084471+00:00  \n",
       "3 2023-03-02 19:14:47.084471+00:00  \n",
       "4 2023-03-02 19:14:47.084471+00:00  \n",
       "5 2023-03-02 19:14:47.084471+00:00  \n",
       "6 2023-03-02 19:14:47.084471+00:00  \n",
       "7 2023-03-02 19:14:47.084471+00:00  \n",
       "8 2023-03-02 19:14:47.084471+00:00  \n",
       "9 2023-03-02 19:14:47.084471+00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select sample data for fun\n",
    "pd.read_sql(text(\"SELECT * from settlement_location order by random() limit 10\"), con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe72365",
   "metadata": {},
   "source": [
    "### todo: Bug: if first append works but primary key fails to create, nothing else will work ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e695114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_insertnew(table_name, primary_keys, df, con):\n",
    "    # insert df into table_name but only if those rows aren't already there\n",
    "    \n",
    "    # make sure the target table exists, but empty (by iloc[0:0])\n",
    "    try: \n",
    "        print (\"pg_insertnew: trying append\", table_name, con)\n",
    "        con.commit() # maybe it needs no outstanding transactions before a DDL?  I think that was it\n",
    "        df.to_sql(table_name, con=con, if_exists='append', index=False); \n",
    "        try_merge=False\n",
    "    except: \n",
    "        print (\"pg_insertnew append failed, rolling back\")\n",
    "        con.rollback();\n",
    "        try_merge=True\n",
    "\n",
    "        print (\"pg_insertnew making sure table has PK\")\n",
    "\n",
    "    # make sure the target table has a primary key(s)\n",
    "    con.execute(text(f\"\"\"\n",
    "    DO $$\n",
    "    BEGIN\n",
    "        if NOT exists (\n",
    "          select constraint_name\n",
    "          from information_schema.table_constraints\n",
    "          where table_name = '{table_name}' \n",
    "          and constraint_type = 'PRIMARY KEY'\n",
    "        ) then ALTER TABLE {table_name}\n",
    "          ADD CONSTRAINT {table_name}_pk PRIMARY KEY ({','.join(primary_keys)});\n",
    "        end if;\n",
    "    end $$\"\"\"))\n",
    "    \n",
    "    con.commit();\n",
    "\n",
    "    if try_merge: \n",
    "#        print (\"trying merge\")\n",
    "        print (f\"pg_insertnew loading {table_name}_stg\")\n",
    "        # load df to a stage table\n",
    "        df.to_sql(f\"{table_name}_stg\", con=con, if_exists='replace', index=False); \n",
    "        con.commit();\n",
    "\n",
    "        # Insert new rows into permanent table\n",
    "        joinstring=''\n",
    "        for k in primary_keys: \n",
    "            if k == primary_keys[0]: \n",
    "                joinstring += f's.{k} = g.{k}'\n",
    "            else:\n",
    "                joinstring += f' and s.{k} = g.{k}'\n",
    "\n",
    "        print (f\"pg_insertnew loading {table_name}_stg to {table_name}\")\n",
    "        con.execute(text(f\"\"\"\n",
    "           insert into {table_name}\n",
    "           select s.* from {table_name}_stg s\n",
    "           left join {table_name} g\n",
    "           on {joinstring}\n",
    "           where g.{primary_keys[0]} IS NULL\n",
    "        \"\"\"))\n",
    "\n",
    "        con.commit();\n",
    "        con.execute (text(f\"\"\"drop table {table_name}_stg\"\"\"))\n",
    "        con.commit();    \n",
    "                     \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b91579",
   "metadata": {},
   "source": [
    "# Generation Mix\n",
    "\n",
    "## todo: handle web server errors like \n",
    "- IncompleteRead: IncompleteRead(4044 bytes read, 2 more expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f4b44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized columns:  ['gmt_mkt_interval' 'coal_market' 'coal_self' 'diesel_fuel_oil_market'\n",
      " 'diesel_fuel_oil_self' 'hydro_market' 'hydro_self' 'natural_gas_market'\n",
      " 'natural_gas_self' 'nuclear_market' 'nuclear_self' 'solar_market'\n",
      " 'solar_self' 'waste_disposal_services_market'\n",
      " 'waste_disposal_services_self' 'wind_market' 'wind_self'\n",
      " 'waste_heat_market' 'waste_heat_self' 'other_market' 'other_self' 'load'\n",
      " 'inserted_time']\n",
      "pg_insertnew: trying append generation_mix <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading generation_mix_stg\n",
      "pg_insertnew loading generation_mix_stg to generation_mix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmt_mkt_interval</th>\n",
       "      <th>coal_market</th>\n",
       "      <th>coal_self</th>\n",
       "      <th>diesel_fuel_oil_market</th>\n",
       "      <th>diesel_fuel_oil_self</th>\n",
       "      <th>hydro_market</th>\n",
       "      <th>hydro_self</th>\n",
       "      <th>natural_gas_market</th>\n",
       "      <th>natural_gas_self</th>\n",
       "      <th>nuclear_market</th>\n",
       "      <th>...</th>\n",
       "      <th>waste_disposal_services_market</th>\n",
       "      <th>waste_disposal_services_self</th>\n",
       "      <th>wind_market</th>\n",
       "      <th>wind_self</th>\n",
       "      <th>waste_heat_market</th>\n",
       "      <th>waste_heat_self</th>\n",
       "      <th>other_market</th>\n",
       "      <th>other_self</th>\n",
       "      <th>load</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 22:05:00+00:00</td>\n",
       "      <td>7585.7</td>\n",
       "      <td>5122.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.9</td>\n",
       "      <td>936.9</td>\n",
       "      <td>9757.3</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3645.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>30763.075</td>\n",
       "      <td>2023-03-08 22:14:48.725867+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:00:00+00:00</td>\n",
       "      <td>7513.3</td>\n",
       "      <td>5151.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.8</td>\n",
       "      <td>936.4</td>\n",
       "      <td>9723.2</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3646.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30704.117</td>\n",
       "      <td>2023-03-08 22:14:48.725867+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 21:55:00+00:00</td>\n",
       "      <td>7472.3</td>\n",
       "      <td>5159.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.5</td>\n",
       "      <td>902.5</td>\n",
       "      <td>9823.9</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3585.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30703.708</td>\n",
       "      <td>2023-03-08 22:14:48.725867+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 21:50:00+00:00</td>\n",
       "      <td>7399.0</td>\n",
       "      <td>5169.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.6</td>\n",
       "      <td>900.9</td>\n",
       "      <td>9754.6</td>\n",
       "      <td>1016.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30673.699</td>\n",
       "      <td>2023-03-08 22:14:48.725867+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 21:45:00+00:00</td>\n",
       "      <td>7348.7</td>\n",
       "      <td>5178.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.5</td>\n",
       "      <td>902.8</td>\n",
       "      <td>9670.3</td>\n",
       "      <td>1027.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3638.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>30609.458</td>\n",
       "      <td>2023-03-08 22:14:48.725867+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gmt_mkt_interval  coal_market  coal_self  diesel_fuel_oil_market  \\\n",
       "0 2023-03-08 22:05:00+00:00       7585.7     5122.1                     5.0   \n",
       "1 2023-03-08 22:00:00+00:00       7513.3     5151.5                     5.0   \n",
       "2 2023-03-08 21:55:00+00:00       7472.3     5159.1                     5.0   \n",
       "3 2023-03-08 21:50:00+00:00       7399.0     5169.9                     5.0   \n",
       "4 2023-03-08 21:45:00+00:00       7348.7     5178.4                     5.0   \n",
       "\n",
       "   diesel_fuel_oil_self  hydro_market  hydro_self  natural_gas_market  \\\n",
       "0                   0.0         187.9       936.9              9757.3   \n",
       "1                   0.0         187.8       936.4              9723.2   \n",
       "2                   0.0         249.5       902.5              9823.9   \n",
       "3                   0.0         249.6       900.9              9754.6   \n",
       "4                   0.0         249.5       902.8              9670.3   \n",
       "\n",
       "   natural_gas_self  nuclear_market  ...  waste_disposal_services_market  \\\n",
       "0            1006.0             0.0  ...                             1.5   \n",
       "1            1005.9             0.0  ...                             1.5   \n",
       "2            1004.5             0.0  ...                             1.4   \n",
       "3            1016.1             0.0  ...                             2.8   \n",
       "4            1027.6             0.0  ...                             2.9   \n",
       "\n",
       "   waste_disposal_services_self  wind_market  wind_self  waste_heat_market  \\\n",
       "0                           7.3          0.0     3645.2                0.0   \n",
       "1                           7.2          0.0     3646.4                0.0   \n",
       "2                           7.3          0.0     3585.3                0.0   \n",
       "3                           7.3          0.0     3610.6                0.0   \n",
       "4                           7.5          0.0     3638.1                0.0   \n",
       "\n",
       "   waste_heat_self  other_market  other_self       load  \\\n",
       "0              0.0           0.0        29.4  30763.075   \n",
       "1              0.0           0.0        29.6  30704.117   \n",
       "2              0.0           0.0        29.6  30703.708   \n",
       "3              0.0           0.0        29.6  30673.699   \n",
       "4              0.0           0.0        29.4  30609.458   \n",
       "\n",
       "                     inserted_time  \n",
       "0 2023-03-08 22:14:48.725867+00:00  \n",
       "1 2023-03-08 22:14:48.725867+00:00  \n",
       "2 2023-03-08 22:14:48.725867+00:00  \n",
       "3 2023-03-08 22:14:48.725867+00:00  \n",
       "4 2023-03-08 22:14:48.725867+00:00  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try something harder: 2 hour generation mix. \n",
    "\n",
    "def update_generation_mix(con):\n",
    "    df=pd.read_csv(\"https://marketplace.spp.org/file-browser-api/download/generation-mix-historical?path=%2FGenMix2Hour.csv\", \n",
    "                   parse_dates=['GMT MKT Interval'], \n",
    "                   infer_datetime_format = True)\n",
    "   \n",
    "    standardize_columns(df)\n",
    "\n",
    "    pg_insertnew(table_name='generation_mix', primary_keys=['gmt_mkt_interval'], df=df, con=con)\n",
    "    \n",
    "    return pgsqldf(\"select * from generation_mix order by gmt_mkt_interval desc limit 5\")\n",
    "\n",
    "# update_generation_mix(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8895ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmt_mkt_interval</th>\n",
       "      <th>local_interval</th>\n",
       "      <th>coal</th>\n",
       "      <th>diesel</th>\n",
       "      <th>hydro</th>\n",
       "      <th>natural_gas</th>\n",
       "      <th>nuclear</th>\n",
       "      <th>solar</th>\n",
       "      <th>wind</th>\n",
       "      <th>other</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 22:05:00+00:00</td>\n",
       "      <td>2023-03-08 16:05:00</td>\n",
       "      <td>12707.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1124.8</td>\n",
       "      <td>10763.3</td>\n",
       "      <td>2026.8</td>\n",
       "      <td>147.0</td>\n",
       "      <td>3645.2</td>\n",
       "      <td>38.2</td>\n",
       "      <td>30763.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:00:00+00:00</td>\n",
       "      <td>2023-03-08 16:00:00</td>\n",
       "      <td>12664.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1124.2</td>\n",
       "      <td>10729.1</td>\n",
       "      <td>2028.1</td>\n",
       "      <td>170.3</td>\n",
       "      <td>3646.4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>30704.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 21:55:00+00:00</td>\n",
       "      <td>2023-03-08 15:55:00</td>\n",
       "      <td>12631.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>10828.4</td>\n",
       "      <td>2027.7</td>\n",
       "      <td>151.6</td>\n",
       "      <td>3585.3</td>\n",
       "      <td>38.3</td>\n",
       "      <td>30703.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 21:50:00+00:00</td>\n",
       "      <td>2023-03-08 15:50:00</td>\n",
       "      <td>12568.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1150.5</td>\n",
       "      <td>10770.7</td>\n",
       "      <td>2026.4</td>\n",
       "      <td>159.5</td>\n",
       "      <td>3610.6</td>\n",
       "      <td>39.7</td>\n",
       "      <td>30673.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 21:45:00+00:00</td>\n",
       "      <td>2023-03-08 15:45:00</td>\n",
       "      <td>12527.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1152.3</td>\n",
       "      <td>10697.9</td>\n",
       "      <td>2028.1</td>\n",
       "      <td>171.2</td>\n",
       "      <td>3638.1</td>\n",
       "      <td>39.8</td>\n",
       "      <td>30609.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-08 21:40:00+00:00</td>\n",
       "      <td>2023-03-08 15:40:00</td>\n",
       "      <td>12475.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1150.1</td>\n",
       "      <td>10699.0</td>\n",
       "      <td>2028.5</td>\n",
       "      <td>180.6</td>\n",
       "      <td>3651.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>30584.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-08 21:35:00+00:00</td>\n",
       "      <td>2023-03-08 15:35:00</td>\n",
       "      <td>12453.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>10727.3</td>\n",
       "      <td>2029.1</td>\n",
       "      <td>182.9</td>\n",
       "      <td>3633.8</td>\n",
       "      <td>39.2</td>\n",
       "      <td>30584.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-08 21:30:00+00:00</td>\n",
       "      <td>2023-03-08 15:30:00</td>\n",
       "      <td>12427.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1151.3</td>\n",
       "      <td>10764.2</td>\n",
       "      <td>2026.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>3658.7</td>\n",
       "      <td>39.1</td>\n",
       "      <td>30618.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-08 21:25:00+00:00</td>\n",
       "      <td>2023-03-08 15:25:00</td>\n",
       "      <td>12408.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1152.6</td>\n",
       "      <td>10778.7</td>\n",
       "      <td>2028.1</td>\n",
       "      <td>190.2</td>\n",
       "      <td>3665.8</td>\n",
       "      <td>38.9</td>\n",
       "      <td>30631.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-08 21:20:00+00:00</td>\n",
       "      <td>2023-03-08 15:20:00</td>\n",
       "      <td>12383.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1151.6</td>\n",
       "      <td>10836.4</td>\n",
       "      <td>2027.2</td>\n",
       "      <td>184.1</td>\n",
       "      <td>3656.6</td>\n",
       "      <td>38.9</td>\n",
       "      <td>30637.417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gmt_mkt_interval      local_interval     coal  diesel   hydro  \\\n",
       "0 2023-03-08 22:05:00+00:00 2023-03-08 16:05:00  12707.8     5.0  1124.8   \n",
       "1 2023-03-08 22:00:00+00:00 2023-03-08 16:00:00  12664.8     5.0  1124.2   \n",
       "2 2023-03-08 21:55:00+00:00 2023-03-08 15:55:00  12631.4     5.0  1152.0   \n",
       "3 2023-03-08 21:50:00+00:00 2023-03-08 15:50:00  12568.9     5.0  1150.5   \n",
       "4 2023-03-08 21:45:00+00:00 2023-03-08 15:45:00  12527.1     5.0  1152.3   \n",
       "5 2023-03-08 21:40:00+00:00 2023-03-08 15:40:00  12475.4     5.0  1150.1   \n",
       "6 2023-03-08 21:35:00+00:00 2023-03-08 15:35:00  12453.6     5.0  1151.0   \n",
       "7 2023-03-08 21:30:00+00:00 2023-03-08 15:30:00  12427.7     5.0  1151.3   \n",
       "8 2023-03-08 21:25:00+00:00 2023-03-08 15:25:00  12408.2     5.0  1152.6   \n",
       "9 2023-03-08 21:20:00+00:00 2023-03-08 15:20:00  12383.6     5.0  1151.6   \n",
       "\n",
       "   natural_gas  nuclear  solar    wind  other       load  \n",
       "0      10763.3   2026.8  147.0  3645.2   38.2  30763.075  \n",
       "1      10729.1   2028.1  170.3  3646.4   38.3  30704.117  \n",
       "2      10828.4   2027.7  151.6  3585.3   38.3  30703.708  \n",
       "3      10770.7   2026.4  159.5  3610.6   39.7  30673.699  \n",
       "4      10697.9   2028.1  171.2  3638.1   39.8  30609.458  \n",
       "5      10699.0   2028.5  180.6  3651.2   39.2  30584.048  \n",
       "6      10727.3   2029.1  182.9  3633.8   39.2  30584.938  \n",
       "7      10764.2   2026.3  188.8  3658.7   39.1  30618.527  \n",
       "8      10778.7   2028.1  190.2  3665.8   38.9  30631.173  \n",
       "9      10836.4   2027.2  184.1  3656.6   38.9  30637.417  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test query, just because I can:\n",
    "\n",
    "pgsqldf(\"\"\"\n",
    "    select gmt_mkt_interval, \n",
    "     gmt_mkt_interval at time zone 'America/Chicago' as local_interval,\n",
    "    coal_market+coal_self as coal,\n",
    "    diesel_fuel_oil_market+diesel_fuel_oil_self as diesel,\n",
    "    hydro_market+hydro_self as hydro,\n",
    "    natural_gas_market+natural_gas_self as natural_gas,\n",
    "    nuclear_market+nuclear_self as nuclear,\n",
    "    solar_market+solar_self as solar,\n",
    "    wind_market+wind_self as wind,\n",
    "    waste_disposal_services_market+waste_disposal_services_self\n",
    "      +waste_heat_market+waste_heat_self\n",
    "      +other_market+other_self as other,\n",
    "    load \n",
    "    from generation_mix\n",
    "    order by gmt_mkt_interval desc\n",
    "    limit 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdfcc39",
   "metadata": {},
   "source": [
    "# RTBM LMP by Settlement Location\n",
    "\n",
    "Depends on:  \n",
    "generation_mix table, for the most recent interval. \n",
    "Will be stored in the ci (current interval) dataframe.\n",
    "\n",
    "### TODO\n",
    " * determine if file names change with DST, and what the duplicate hour in November looks like\n",
    " * switch to grabbing that \"latest interval\" file\n",
    "     * on FTP at pubftp.spp.org/Markets/RTBM/LMP_By_SETTLEMENT_LOC/RTBM-LMP-SL-latestInterval.csv \n",
    "     * on HTTPS at https://marketplace.spp.org/file-browser-api/download/rtbm-lmp-by-location?path=%2FRTBM-LMP-SL-latestInterval.csv\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44502070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt_yyyy</th>\n",
       "      <th>rt_mm</th>\n",
       "      <th>rt_dd</th>\n",
       "      <th>rt_hh24</th>\n",
       "      <th>rt_mi</th>\n",
       "      <th>da_yyyy</th>\n",
       "      <th>da_mm</th>\n",
       "      <th>da_dd</th>\n",
       "      <th>da_hh24</th>\n",
       "      <th>pathda_hh24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>03</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>03</td>\n",
       "      <td>08</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rt_yyyy rt_mm rt_dd rt_hh24 rt_mi da_yyyy da_mm da_dd da_hh24 pathda_hh24\n",
       "0    2023    03    08      16    10    2023    03    08      17          17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_current_interval(): \n",
    "    retdf = pgsqldf(\"\"\"\n",
    "    with c as (\n",
    "        select max(gmt_mkt_interval) at time zone 'America/Chicago' as interval_cpt\n",
    "        from generation_mix\n",
    "    )\n",
    "    , intervalmunge as (\n",
    "        select interval_cpt, \n",
    "        '1970-01-01 00:00:00'::timestamp + (interval '5 minutes' * (floor(extract(EPOCH from interval_cpt)::numeric / 300.0) + 1)) as interval_end_cpt,\n",
    "        '1970-01-01 00:00:00'::timestamp + (interval '1 hour' * (floor(extract(EPOCH from interval_cpt)::numeric / 3600.0) + 1)) as hour_end_cpt,\n",
    "        '1970-01-01 00:00:00'::timestamp + (interval '1 hour' * (floor(extract(EPOCH from (interval_cpt + interval '5 minutes'))::numeric / 3600.0) + 1)) as pathhour_end_cpt  \n",
    "        from c\n",
    "    )\n",
    "    select \n",
    "/*     date_part('year', interval_end_cpt)::char as rt_yyyy,\n",
    "    lpad(date_part('month', interval_end_cpt)::char, 2, '0') as rt_mm,\n",
    "    lpad(date_part('day', interval_end_cpt)::char, 2, '0') as rt_dd,\n",
    "    lpad(date_part('hour', interval_end_cpt)::char, 2, '0') as rt_hh24,\n",
    "    lpad(date_part('minute', interval_end_cpt)::char, 2, '0') as rt_mi,\n",
    "*/\n",
    "    to_char(interval_end_cpt, 'YYYY') as rt_yyyy,\n",
    "    to_char(interval_end_cpt, 'MM') as rt_mm,\n",
    "    to_char(interval_end_cpt, 'DD') as rt_dd,\n",
    "    to_char(interval_end_cpt, 'HH24') as rt_hh24,\n",
    "    to_char(interval_end_cpt, 'MI') as rt_mi,\n",
    "    \n",
    "    to_char(hour_end_cpt, 'YYYY') as da_yyyy,\n",
    "    to_char(hour_end_cpt, 'MM') as da_mm,\n",
    "    to_char(hour_end_cpt, 'DD') as da_dd,\n",
    "    to_char(hour_end_cpt, 'HH24') as da_hh24,\n",
    "    to_char(pathhour_end_cpt, 'HH24') as pathda_hh24\n",
    "    \n",
    "    from intervalmunge\n",
    "    \"\"\")\n",
    "    return retdf\n",
    "\n",
    "con.rollback()\n",
    "get_current_interval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530c8c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating RTBM data from current interval: True\n",
      "reading https://marketplace.spp.org/file-browser-api/download/rtbm-lmp-by-location?path=%2F2023%2F03%2FBy_Interval%2F08%2FRTBM-LMP-SL-202303081610.csv\n",
      "standardized columns:  ['interval' 'gmtinterval_end' 'settlement_location' 'pnode' 'lmp' 'mlc'\n",
      " 'mcc' 'mec' 'inserted_time']\n",
      "pg_insertnew: trying append rtbm_lmp_by_location <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmtinterval_end</th>\n",
       "      <th>settlement_location</th>\n",
       "      <th>pnode</th>\n",
       "      <th>lmp</th>\n",
       "      <th>mlc</th>\n",
       "      <th>mcc</th>\n",
       "      <th>mec</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 22:10:00+00:00</td>\n",
       "      <td>OKGE.VOLT.0029</td>\n",
       "      <td>GLENDALE_DDR</td>\n",
       "      <td>74.8606</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.3540</td>\n",
       "      <td>2023-03-08 22:14:50.394119+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:10:00+00:00</td>\n",
       "      <td>SPS.VOLT.0045</td>\n",
       "      <td>SPSDOLLARHIUNDLHD_DDR_GEN_RA</td>\n",
       "      <td>77.2911</td>\n",
       "      <td>2.9371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.3540</td>\n",
       "      <td>2023-03-08 22:14:50.394119+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 22:10:00+00:00</td>\n",
       "      <td>WR.AEPE.FLATRIDGE3</td>\n",
       "      <td>WRVIOLA7UNFLATRDG3_AEPE_RA</td>\n",
       "      <td>73.4053</td>\n",
       "      <td>-0.9487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.3540</td>\n",
       "      <td>2023-03-08 22:14:50.394119+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 22:10:00+00:00</td>\n",
       "      <td>GSPR2015HUB</td>\n",
       "      <td>GSPR2015HUB_H</td>\n",
       "      <td>72.4690</td>\n",
       "      <td>-1.8850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.3540</td>\n",
       "      <td>2023-03-08 22:14:50.394119+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 22:10:00+00:00</td>\n",
       "      <td>GSPWR</td>\n",
       "      <td>SPSGSPWRUNGSPWR_WIND_RA</td>\n",
       "      <td>71.5397</td>\n",
       "      <td>-2.8144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.3541</td>\n",
       "      <td>2023-03-08 22:14:50.394119+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gmtinterval_end settlement_location                         pnode  \\\n",
       "0 2023-03-08 22:10:00+00:00      OKGE.VOLT.0029                  GLENDALE_DDR   \n",
       "1 2023-03-08 22:10:00+00:00       SPS.VOLT.0045  SPSDOLLARHIUNDLHD_DDR_GEN_RA   \n",
       "2 2023-03-08 22:10:00+00:00  WR.AEPE.FLATRIDGE3    WRVIOLA7UNFLATRDG3_AEPE_RA   \n",
       "3 2023-03-08 22:10:00+00:00         GSPR2015HUB                 GSPR2015HUB_H   \n",
       "4 2023-03-08 22:10:00+00:00               GSPWR       SPSGSPWRUNGSPWR_WIND_RA   \n",
       "\n",
       "       lmp     mlc  mcc      mec                    inserted_time  \n",
       "0  74.8606  0.5066  0.0  74.3540 2023-03-08 22:14:50.394119+00:00  \n",
       "1  77.2911  2.9371  0.0  74.3540 2023-03-08 22:14:50.394119+00:00  \n",
       "2  73.4053 -0.9487  0.0  74.3540 2023-03-08 22:14:50.394119+00:00  \n",
       "3  72.4690 -1.8850  0.0  74.3540 2023-03-08 22:14:50.394119+00:00  \n",
       "4  71.5397 -2.8144  0.0  74.3541 2023-03-08 22:14:50.394119+00:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_rtbm_lmp(con):\n",
    "    # Pull out of generation_mix the most recent interval, in a format needed to get other information: \n",
    "    ci = get_current_interval()\n",
    "    \n",
    "    rt_yyyy=ci.rt_yyyy.values[0]\n",
    "    rt_mm  =ci.rt_mm.values[0]\n",
    "    rt_dd  =ci.rt_dd.values[0]\n",
    "    rt_hh24  =ci.rt_hh24.values[0]\n",
    "    rt_mi  =ci.rt_mi.values[0]\n",
    "\n",
    "    # if this interval exists already in rtbm_lmp_by_location, skip the rest\n",
    "    try: \n",
    "        rtbm_db_df=pgsqldf(f\"\"\"\n",
    "        select *\n",
    "        from rtbm_lmp_by_location\n",
    "        where (gmtinterval_end at time zone 'America/Chicago') = '{rt_yyyy}-{rt_mm}-{rt_dd} {rt_hh24}:{rt_mi}:00'\n",
    "        limit 5\n",
    "        \"\"\")\n",
    "\n",
    "        assert len(rtbm_db_df.index) > 0\n",
    "\n",
    "        return rtbm_db_df\n",
    "            \n",
    "    except: \n",
    "        get_rtbm=True\n",
    "\n",
    "    print (\"updating RTBM data from current interval:\", get_rtbm)\n",
    "\n",
    "    fpath=f\"https://marketplace.spp.org/file-browser-api/download/rtbm-lmp-by-location?\" + \\\n",
    "          f\"path=%2F{rt_yyyy}%2F{rt_mm}%2FBy_Interval%2F{rt_dd}%2F\" + \\\n",
    "          f\"RTBM-LMP-SL-{rt_yyyy}{rt_mm}{rt_dd}{rt_hh24}{rt_mi}.csv\"\n",
    "\n",
    "# todo:  handle 404 gracefully.  Sometimes the RTBM doesn't solve. \n",
    "\n",
    "    print (f\"reading {fpath}\")\n",
    "\n",
    "    dfnew=pd.read_csv(fpath, parse_dates=['GMTIntervalEnd'], \n",
    "                   infer_datetime_format = True)\n",
    "\n",
    "    \"\"\"\n",
    "    dfnew.rename(columns={'Interval':'interval', 'GMTIntervalEnd':'gmt_interval_end', 'Settlement Location':'settlement_location',\n",
    "                   'Pnode':'pnode', 'LMP':'lmp', 'MLC':'mlc', 'MCC':'mcc', 'MEC':'mec'}, inplace=True)\n",
    "    \"\"\" \n",
    "#   in this source file, GMTIntervalEnd does not have a timezone.  Add it: \n",
    "    from datetime import timezone\n",
    "    dfnew['GMTIntervalEnd'] = dfnew['GMTIntervalEnd'].dt.tz_localize(timezone.utc)\n",
    "\n",
    "    standardize_columns(dfnew)\n",
    "    \n",
    "# interval is now redundant \n",
    "    dfnew.drop(axis='columns', columns=['interval'], inplace=True)\n",
    "\n",
    "#    return dfnew\n",
    "\n",
    "    # insert rows that don't already exist\n",
    "    \n",
    "    pg_insertnew('rtbm_lmp_by_location', ['gmtinterval_end', 'settlement_location'], dfnew, con)\n",
    "        \n",
    "    con.commit()    \n",
    "    \n",
    "    rtbm_db_df=pgsqldf(f\"\"\"\n",
    "       SELECT * \n",
    "       from rtbm_lmp_by_location \n",
    "       order by gmtinterval_end desc, random() limit 5\n",
    "    \"\"\")\n",
    "    return rtbm_db_df   \n",
    "\n",
    "#con.rollback()\n",
    "#update_rtbm_lmp(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47034aee",
   "metadata": {},
   "source": [
    "# DA LMP by Settlement Location\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bd612e",
   "metadata": {},
   "source": [
    "# TODO: fix the test in RTBM and DALMP that used 'interval' to determine if it needed to reload. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8b6f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmtinterval_end</th>\n",
       "      <th>settlement_location</th>\n",
       "      <th>pnode</th>\n",
       "      <th>lmp</th>\n",
       "      <th>mlc</th>\n",
       "      <th>mcc</th>\n",
       "      <th>mec</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 23:00:00+00:00</td>\n",
       "      <td>AEC</td>\n",
       "      <td>SOUC</td>\n",
       "      <td>36.4822</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>1.9102</td>\n",
       "      <td>33.757</td>\n",
       "      <td>2023-03-08 06:07:26.240155+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 23:00:00+00:00</td>\n",
       "      <td>AECC_CSWS</td>\n",
       "      <td>CSWS_AECC_LA</td>\n",
       "      <td>35.1323</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.4514</td>\n",
       "      <td>33.757</td>\n",
       "      <td>2023-03-08 06:07:26.240155+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 23:00:00+00:00</td>\n",
       "      <td>AECC_ELKINS</td>\n",
       "      <td>CSWSELKINSUNELKINS_RA</td>\n",
       "      <td>34.8436</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>33.757</td>\n",
       "      <td>2023-03-08 06:07:26.240155+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 23:00:00+00:00</td>\n",
       "      <td>AECC_FITZHUGH</td>\n",
       "      <td>CSWSFITZHUGHPLT1</td>\n",
       "      <td>35.6052</td>\n",
       "      <td>1.1357</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>33.757</td>\n",
       "      <td>2023-03-08 06:07:26.240155+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 23:00:00+00:00</td>\n",
       "      <td>AECC_FLTCREEK</td>\n",
       "      <td>CSWSFLINTCRKUN1_JOU_AECC_RA</td>\n",
       "      <td>34.5853</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>33.757</td>\n",
       "      <td>2023-03-08 06:07:26.240155+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gmtinterval_end settlement_location                        pnode  \\\n",
       "0 2023-03-08 23:00:00+00:00                 AEC                         SOUC   \n",
       "1 2023-03-08 23:00:00+00:00           AECC_CSWS                 CSWS_AECC_LA   \n",
       "2 2023-03-08 23:00:00+00:00         AECC_ELKINS        CSWSELKINSUNELKINS_RA   \n",
       "3 2023-03-08 23:00:00+00:00       AECC_FITZHUGH             CSWSFITZHUGHPLT1   \n",
       "4 2023-03-08 23:00:00+00:00       AECC_FLTCREEK  CSWSFLINTCRKUN1_JOU_AECC_RA   \n",
       "\n",
       "       lmp     mlc     mcc     mec                    inserted_time  \n",
       "0  36.4822  0.8150  1.9102  33.757 2023-03-08 06:07:26.240155+00:00  \n",
       "1  35.1323  0.9239  0.4514  33.757 2023-03-08 06:07:26.240155+00:00  \n",
       "2  34.8436  0.9876  0.0990  33.757 2023-03-08 06:07:26.240155+00:00  \n",
       "3  35.6052  1.1357  0.7125  33.757 2023-03-08 06:07:26.240155+00:00  \n",
       "4  34.5853  0.6856  0.1427  33.757 2023-03-08 06:07:26.240155+00:00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_da_lmp(con):\n",
    "    # Pull out of generation_mix the most recent interval, in a format needed to get other information: \n",
    "    ci = get_current_interval()\n",
    "    \n",
    "    da_yyyy=ci.da_yyyy.values[0]\n",
    "    da_mm  =ci.da_mm.values[0]\n",
    "    da_dd  =ci.da_dd.values[0]\n",
    "    da_hh24  =ci.da_hh24.values[0]\n",
    "\n",
    "        # if this interval exists already in da_lmp_by_location, skip the rest\n",
    "    try: \n",
    "        da_db_df=pgsqldf(f\"\"\"\n",
    "        select *\n",
    "        from da_lmp_by_location\n",
    "        where (gmtinterval_end at time zone 'America/Chicago') = '{da_yyyy}-{da_mm}-{da_dd} {da_hh24}:00:00'\n",
    "        limit 5\n",
    "        \"\"\")\n",
    "\n",
    "        assert len(da_db_df.index) > 0\n",
    "\n",
    "        return da_db_df\n",
    "    except: \n",
    "        get_da=True\n",
    "\n",
    "    print (\"updating DA data from current interval:\", get_da)\n",
    "\n",
    "    fpath=f\"https://marketplace.spp.org/file-browser-api/download/da-lmp-by-location?\" + \\\n",
    "          f\"path=%2F{da_yyyy}%2F{da_mm}%2FBy_Day%2FDA-LMP-SL-{da_yyyy}{da_mm}{da_dd}0100.csv\"\n",
    "        \n",
    "    print (f\"reading {fpath}\")\n",
    "\n",
    "    try: \n",
    "        # these are big; if I've already run once today it is cached\n",
    "        dfnew=pd.read_pickle(f\"DA-LMP-SL-{da_yyyy}{da_mm}{da_dd}0100.pickle\")\n",
    "        print (f\"read local cached version DA-LMP-SL-{da_yyyy}{da_mm}{da_dd}0100.pickle\")\n",
    "    except: \n",
    "        dfnew=pd.read_csv(fpath, parse_dates=['GMTIntervalEnd'], \n",
    "                   infer_datetime_format = True)\n",
    "        dfnew.to_pickle(f\"DA-LMP-SL-{da_yyyy}{da_mm}{da_dd}0100.pickle\")\n",
    "        print (f\"saved local cached version DA-LMP-SL-{da_yyyy}{da_mm}{da_dd}0100.pickle\")\n",
    "    \"\"\"\n",
    "    dfnew.rename(columns={'Interval':'interval', 'GMTIntervalEnd':'gmt_interval_end', 'Settlement Location':'settlement_location',\n",
    "                   'Pnode':'pnode', 'LMP':'lmp', 'MLC':'mlc', 'MCC':'mcc', 'MEC':'mec'}, inplace=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    #   in this source file, GMTIntervalEnd does not have a timezone.  Add it: \n",
    "    from datetime import timezone\n",
    "    dfnew['GMTIntervalEnd'] = dfnew['GMTIntervalEnd'].dt.tz_localize(timezone.utc)\n",
    "\n",
    "    standardize_columns(dfnew)\n",
    "# interval is now redundant \n",
    "    dfnew.drop(axis='columns', columns=['interval'], inplace=True)\n",
    "\n",
    "    \n",
    "    # insert rows that don't already exist\n",
    "    pg_insertnew('da_lmp_by_location', ['gmtinterval_end', 'settlement_location'], dfnew, con)\n",
    "        \n",
    "    con.commit()    \n",
    "    \n",
    "    da_db_df=pgsqldf(f\"\"\"\n",
    "       SELECT * \n",
    "       from da_lmp_by_location \n",
    "       order by gmtinterval_end desc, random() limit 5\n",
    "       \"\"\")\n",
    "    return da_db_df   \n",
    "\n",
    "#con.rollback()\n",
    "#update_da_lmp(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9fbd8",
   "metadata": {},
   "source": [
    "# Area Control Error\n",
    "    ftp://pubftp.spp.org/Operational_Data/ACE/ACE.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c52a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GMTTime' 'Value']\n",
      "standardized columns:  ['gmttime' 'value' 'inserted_time']\n",
      "Index(['gmttime', 'value', 'inserted_time'], dtype='object')\n",
      "pg_insertnew: trying append area_control_error <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading area_control_error_stg\n",
      "pg_insertnew loading area_control_error_stg to area_control_error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmttime</th>\n",
       "      <th>value</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 22:14:00+00:00</td>\n",
       "      <td>51.9567</td>\n",
       "      <td>2023-03-08 22:14:51.926166+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:13:00+00:00</td>\n",
       "      <td>62.1099</td>\n",
       "      <td>2023-03-08 22:14:51.926166+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 22:12:00+00:00</td>\n",
       "      <td>68.2761</td>\n",
       "      <td>2023-03-08 22:14:51.926166+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 22:11:00+00:00</td>\n",
       "      <td>71.0122</td>\n",
       "      <td>2023-03-08 22:14:51.926166+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 22:10:00+00:00</td>\n",
       "      <td>119.5381</td>\n",
       "      <td>2023-03-08 22:14:51.926166+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    gmttime     value                    inserted_time\n",
       "0 2023-03-08 22:14:00+00:00   51.9567 2023-03-08 22:14:51.926166+00:00\n",
       "1 2023-03-08 22:13:00+00:00   62.1099 2023-03-08 22:14:51.926166+00:00\n",
       "2 2023-03-08 22:12:00+00:00   68.2761 2023-03-08 22:14:51.926166+00:00\n",
       "3 2023-03-08 22:11:00+00:00   71.0122 2023-03-08 22:14:51.926166+00:00\n",
       "4 2023-03-08 22:10:00+00:00  119.5381 2023-03-08 22:14:51.926166+00:00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_ace(con):\n",
    "    table_name=\"area_control_error\"\n",
    "    source_url=\"ftp://pubftp.spp.org/Operational_Data/ACE/ACE.csv\"\n",
    "    primary_keys=['gmttime']\n",
    "    \n",
    "    df=pd.read_csv(source_url, \n",
    "                   parse_dates=['GMTTime'], \n",
    "                   infer_datetime_format = True\n",
    "                  )\n",
    "    \n",
    "    print (df.columns.values)\n",
    "    \n",
    "    # df.rename(columns={'GMTTime':'gmt_time', 'Value':'value'}, inplace=True)\n",
    "    standardize_columns(df)  \n",
    "    print(df.columns)\n",
    "    \n",
    "    pg_insertnew(table_name=table_name, primary_keys=primary_keys, df=df, con=con)\n",
    "    \n",
    "    con.commit()\n",
    "    \n",
    "    return pgsqldf(f\"select * from {table_name} order by gmttime desc limit 5\")\n",
    "\n",
    "#update_ace(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e819b",
   "metadata": {},
   "source": [
    "# STLF vs. Actual\n",
    "    https://marketplace.spp.org/file-browser-api/download/stlf-vs-actual?path=%2F2023%2F02%2F25%2F15%2FOP-STLF-202302251435.csv\n",
    "    \n",
    "## TODO:  this one is strange; is there a file with more data?  If not, \n",
    "## need to figure out how replace older rows with newer ones while keeping ones that have already aged out\n",
    "\n",
    "DONE - maybe delete rows with NULLs in Actual column before inserting new values?  If done in one transaction \n",
    "    * already done in Tie Flows; just do that\n",
    "- need to remove commits from the pg_insertnew to keep client from seeing missing data between delete and insert\n",
    "\n",
    "- at 23:30, tried to read\n",
    "https://marketplace.spp.org/file-browser-api/download/stlf-vs-actual?path=/2023/03/01/23/OP-STLF-202303012330.csv\n",
    "- but it is not there; latest file is pubftp.spp.org/Operational_Data/STLF/2023/03/01/00/OP-STLF-202303012330.csv\n",
    "\n",
    "## fix start-of-hour 404: \n",
    "## at about 11:03, this was 404: \n",
    "    #  https://marketplace.spp.org/file-browser-api/download/stlf-vs-actual?path=/2023/03/02/11/OP-STLF-202303021100.csv\n",
    "    # found here\n",
    "    #  https://marketplace.spp.org/file-browser-api/download/stlf-vs-actual?path=/2023/03/02/12/OP-STLF-202303021100.csv\n",
    "    # so the value of da_hh24 in the path had already advanced, 5 minutes early\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3e5444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading https://marketplace.spp.org/file-browser-api/download/stlf-vs-actual?path=%2F2023%2F03%2F08%2F17%2FOP-STLF-202303081610.csv\n",
      "['Interval' 'GMTIntervalEnd' 'STLF' 'Actual']\n",
      "              Interval      GMTIntervalEnd   STLF   Actual\n",
      "0  03/08/2023 16:20:00 2023-03-08 22:20:00  30867      NaN\n",
      "1  03/08/2023 16:15:00 2023-03-08 22:15:00  30840      NaN\n",
      "2  03/08/2023 16:10:00 2023-03-08 22:10:00  30853  30851.0\n",
      "3  03/08/2023 16:05:00 2023-03-08 22:05:00  30794  30842.0\n",
      "standardized columns:  ['interval' 'gmtinterval_end' 'stlf' 'actual' 'inserted_time']\n",
      "pg_insertnew: trying append stlf_vs_actual <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmtinterval_end</th>\n",
       "      <th>stlf</th>\n",
       "      <th>actual</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 22:20:00+00:00</td>\n",
       "      <td>30867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-08 22:14:52.382245+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:15:00+00:00</td>\n",
       "      <td>30840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-08 22:14:52.382245+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 22:10:00+00:00</td>\n",
       "      <td>30853</td>\n",
       "      <td>30851.0</td>\n",
       "      <td>2023-03-08 22:14:52.382245+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 22:05:00+00:00</td>\n",
       "      <td>30794</td>\n",
       "      <td>30842.0</td>\n",
       "      <td>2023-03-08 22:14:52.382245+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 21:40:00+00:00</td>\n",
       "      <td>30675</td>\n",
       "      <td>30714.0</td>\n",
       "      <td>2023-03-08 21:43:25.533105+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gmtinterval_end   stlf   actual                    inserted_time\n",
       "0 2023-03-08 22:20:00+00:00  30867      NaN 2023-03-08 22:14:52.382245+00:00\n",
       "1 2023-03-08 22:15:00+00:00  30840      NaN 2023-03-08 22:14:52.382245+00:00\n",
       "2 2023-03-08 22:10:00+00:00  30853  30851.0 2023-03-08 22:14:52.382245+00:00\n",
       "3 2023-03-08 22:05:00+00:00  30794  30842.0 2023-03-08 22:14:52.382245+00:00\n",
       "4 2023-03-08 21:40:00+00:00  30675  30714.0 2023-03-08 21:43:25.533105+00:00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_stlf(con):\n",
    "    \n",
    "    # Pull out of generation_mix the most recent interval, in a format needed to get other information: \n",
    "    ci = get_current_interval()\n",
    "    \n",
    "    rt_yyyy=ci.rt_yyyy.values[0]\n",
    "    da_yyyy=ci.da_yyyy.values[0]\n",
    "    rt_mm  =ci.rt_mm.values[0]\n",
    "    da_mm  =ci.da_mm.values[0]\n",
    "    rt_dd  =ci.rt_dd.values[0]\n",
    "    da_dd  =ci.da_dd.values[0]\n",
    "    rt_hh24  =ci.rt_hh24.values[0]\n",
    "    da_hh24  =ci.da_hh24.values[0]\n",
    "    pathda_hh24  =ci.pathda_hh24.values[0]\n",
    "    rt_mi  =ci.rt_mi.values[0]\n",
    "    \n",
    "    table_name=\"stlf_vs_actual\"\n",
    "    \n",
    "    source_url=f\"https://marketplace.spp.org/file-browser-api/download/stlf-vs-actual?\" + \\\n",
    "               f\"path=%2F{rt_yyyy}%2F{rt_mm}%2F{rt_dd}%2F{pathda_hh24}%2FOP-STLF-{rt_yyyy}{rt_mm}{rt_dd}{rt_hh24}{rt_mi}.csv\"\n",
    "    primary_keys=['gmtinterval_end']\n",
    "    \n",
    "    print (\"reading\", source_url)\n",
    "    \n",
    "    df=pd.read_csv(source_url, \n",
    "                   parse_dates=['GMTInterval'], \n",
    "                   infer_datetime_format = True\n",
    "                  )\n",
    "\n",
    "    # fix this one error - end was left off of this table's timestamp\n",
    "    df.rename(columns={'GMTInterval':'GMTIntervalEnd'}, inplace=True)\n",
    "\n",
    "    print (df.columns.values)\n",
    "    print (df)\n",
    "        \n",
    "#   in this source file, GMTIntervalEnd does not have a timezone.  Add it: \n",
    "    from datetime import timezone\n",
    "    df['GMTIntervalEnd'] = df['GMTIntervalEnd'].dt.tz_localize(timezone.utc)\n",
    "        \n",
    "    standardize_columns(df)  \n",
    "# interval is now redundant \n",
    "    df.drop(axis='columns', columns=['interval'], inplace=True)\n",
    "\n",
    "    con.commit();\n",
    "    \n",
    "    try:\n",
    "        con.execute(text(\"\"\"delete from stlf_vs_actual where actual is null\"\"\")); \n",
    "        con.commit(); \n",
    "    except: \n",
    "        con.rollback();\n",
    "\n",
    "    pg_insertnew(table_name=table_name, primary_keys=primary_keys, df=df, con=con)\n",
    "    \n",
    "    con.commit()\n",
    "        \n",
    "    return pgsqldf(f\"select * from {table_name} order by gmtinterval_end desc limit 5\")\n",
    "\n",
    "\n",
    "#update_stlf(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046c525",
   "metadata": {},
   "source": [
    "# MTLF Vs. Actual\n",
    "    https://marketplace.spp.org/file-browser-api/download/mtlf-vs-actual?path=%2F2023%2F02%2F25%2FOP-MTLF-202302251600.csv\n",
    "    \n",
    "## Todo:  \n",
    "DONE same thing as STLF re null values\n",
    "- this is kind of big and doesn't update but once an hour; maybe cache the file?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4df637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_mltf: gmtinterval_end '2023-03-08 17:00:00' not yet in database\n",
      "reading https://marketplace.spp.org/file-browser-api/download/mtlf-vs-actual?path=%2F2023%2F03%2F08%2FOP-MTLF-202303081600.csv\n",
      "standardized columns:  ['interval' 'gmtinterval_end' 'mtlf' 'averaged_actual' 'inserted_time']\n",
      "pg_insertnew: trying append mtlf_vs_actual <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading mtlf_vs_actual_stg\n",
      "pg_insertnew loading mtlf_vs_actual_stg to mtlf_vs_actual\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmtinterval_end</th>\n",
       "      <th>mtlf</th>\n",
       "      <th>averaged_actual</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 23:00:00+00:00</td>\n",
       "      <td>30535</td>\n",
       "      <td>30842.0</td>\n",
       "      <td>2023-03-08 22:14:52.798231+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:00:00+00:00</td>\n",
       "      <td>30325</td>\n",
       "      <td>30712.0</td>\n",
       "      <td>2023-03-08 21:07:23.733153+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 21:00:00+00:00</td>\n",
       "      <td>30482</td>\n",
       "      <td>30931.0</td>\n",
       "      <td>2023-03-08 20:07:23.210850+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 20:00:00+00:00</td>\n",
       "      <td>30769</td>\n",
       "      <td>31070.0</td>\n",
       "      <td>2023-03-08 19:07:23.337555+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 19:00:00+00:00</td>\n",
       "      <td>30940</td>\n",
       "      <td>31407.0</td>\n",
       "      <td>2023-03-08 18:07:26.134751+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gmtinterval_end   mtlf  averaged_actual  \\\n",
       "0 2023-03-08 23:00:00+00:00  30535          30842.0   \n",
       "1 2023-03-08 22:00:00+00:00  30325          30712.0   \n",
       "2 2023-03-08 21:00:00+00:00  30482          30931.0   \n",
       "3 2023-03-08 20:00:00+00:00  30769          31070.0   \n",
       "4 2023-03-08 19:00:00+00:00  30940          31407.0   \n",
       "\n",
       "                     inserted_time  \n",
       "0 2023-03-08 22:14:52.798231+00:00  \n",
       "1 2023-03-08 21:07:23.733153+00:00  \n",
       "2 2023-03-08 20:07:23.210850+00:00  \n",
       "3 2023-03-08 19:07:23.337555+00:00  \n",
       "4 2023-03-08 18:07:26.134751+00:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_mtlf(con):\n",
    "    \n",
    "    # Pull out of generation_mix the most recent interval, in a format needed to get other information: \n",
    "    ci = get_current_interval()\n",
    "    \n",
    "    rt_yyyy=ci.rt_yyyy.values[0]\n",
    "    da_yyyy=ci.da_yyyy.values[0]\n",
    "    rt_mm  =ci.rt_mm.values[0]\n",
    "    da_mm  =ci.da_mm.values[0]\n",
    "    rt_dd  =ci.rt_dd.values[0]\n",
    "    da_dd  =ci.da_dd.values[0]\n",
    "    rt_hh24  =ci.rt_hh24.values[0]\n",
    "    da_hh24  =ci.da_hh24.values[0]\n",
    "    rt_mi  =ci.rt_mi.values[0]\n",
    "    \n",
    "    table_name=\"mtlf_vs_actual\"\n",
    "    source_url=f\"https://marketplace.spp.org/file-browser-api/download/mtlf-vs-actual?\" + \\\n",
    "               f\"path=%2F{rt_yyyy}%2F{rt_mm}%2F{rt_dd}%2FOP-MTLF-{rt_yyyy}{rt_mm}{rt_dd}{rt_hh24}00.csv\"\n",
    "    primary_keys=['gmtinterval_end']\n",
    "    \n",
    "    \n",
    "    # if this interval exists already in the database, don't do this update\n",
    "    try: \n",
    "        test_df=pgsqldf(f\"\"\"\n",
    "        select *\n",
    "        from mtlf_vs_actual\n",
    "        where gmtinterval_end = '{da_yyyy}-{da_mm}-{da_dd} {da_hh24}:00:00'\n",
    "        and averaged_actual is NOT NULL\n",
    "        limit 5\n",
    "        \"\"\")\n",
    "\n",
    "        assert len(test_df.index) > 0\n",
    "\n",
    "        print (f\"update_mltf: found '{da_yyyy}-{da_mm}-{da_dd} {da_hh24}:00:00' already in database\")\n",
    "        return test_df\n",
    "            \n",
    "    except: \n",
    "        print (f\"update_mltf: gmtinterval_end '{da_yyyy}-{da_mm}-{da_dd} {da_hh24}:00:00' not yet in database\")\n",
    "        get_rtbm=True\n",
    "    \n",
    "    \n",
    "    print (\"reading\", source_url)\n",
    "    \n",
    "    # this file is not huge but consider caching it locally instead of reading from remote 12 times an hour\n",
    "    # or, better, test the database to see if we need to update it.\n",
    "    \n",
    "    df=pd.read_csv(source_url, \n",
    "                   parse_dates=['GMTIntervalEnd'], \n",
    "                   infer_datetime_format = True\n",
    "                  )\n",
    "        \n",
    "    # df.rename(columns={'Interval':'interval', 'GMTIntervalEnd':'gmt_interval_end', 'MTLF':'mtlf', 'Averaged Actual':'averaged_actual'}, inplace=True)\n",
    "    \n",
    "    #   in this source file, GMTIntervalEnd does not have a timezone.  Add it: \n",
    "    from datetime import timezone\n",
    "    df['GMTIntervalEnd'] = df['GMTIntervalEnd'].dt.tz_localize(timezone.utc)\n",
    "    \n",
    "    standardize_columns(df)  \n",
    "\n",
    "    # interval is now redundant \n",
    "    df.drop(axis='columns', columns=['interval'], inplace=True)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        con.execute(text(\"\"\"delete from mtlf_vs_actual where averaged_actual is null\"\"\")); \n",
    "        con.commit(); \n",
    "    except: \n",
    "        con.rollback();\n",
    "        \n",
    "\n",
    "    pg_insertnew(table_name=table_name, primary_keys=primary_keys, df=df, con=con)\n",
    "    \n",
    "    con.commit()\n",
    "        \n",
    "    return pgsqldf(f\"select * from {table_name} where averaged_actual is not null order by gmtinterval_end desc limit 5\")\n",
    "\n",
    "#update_mtlf(con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b14d1e",
   "metadata": {},
   "source": [
    "# Tie Flows\n",
    "    ftp://pubftp.spp.org/Operational_Data/TIE_FLOW/TieFlows.csv\n",
    "    \n",
    "## TODO: \n",
    "- Implement periodic vacuum from all these deletes\n",
    "\n",
    "- Completely refactor to convert wide-form data to long-form data.  That would avoid completely breaking this interface if an area is added, removed or renamed.\n",
    "    * AND it would completely fix the delete problem by not inserting NULL values in the first place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96adb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEPRECATED fragile wide-form; if the layout changes, we have to redo everything.  See now update_tie_flows_long. \n",
    "def update_tie_flows(con):\n",
    "    return; \n",
    "\n",
    "    table_name=\"tie_flows\"\n",
    "    source_url=\"ftp://pubftp.spp.org/Operational_Data/TIE_FLOW/TieFlows.csv\"\n",
    "    primary_keys=['gmttime']\n",
    "    \n",
    "    df=pd.read_csv(source_url, \n",
    "                   parse_dates=['GMTTime'], \n",
    "                   infer_datetime_format = True\n",
    "                  )\n",
    "    \n",
    "    #df.rename(columns={'GMTTime':'gmt_time'}, inplace=True)\n",
    "    standardize_columns(df)\n",
    "    \n",
    "    try:\n",
    "        con.execute(text(\"\"\"delete from tie_flows where spp_nsi is null\"\"\"))\n",
    "        con.commit() \n",
    "    except: \n",
    "        con.rollback()\n",
    "        \n",
    "    pg_insertnew(table_name=table_name, primary_keys=primary_keys, df=df, con=con)\n",
    "    \n",
    "    con.commit()\n",
    "    \n",
    "    return pgsqldf(f\"\"\"select * from {table_name} where spp_nsi is not null order by gmttime desc limit 5\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6efa91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized columns:  ['gmttime' 'area' 'mw' 'inserted_time']\n",
      "pg_insertnew: trying append tie_flows_long <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmttime</th>\n",
       "      <th>area</th>\n",
       "      <th>mw</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 22:13:00+00:00</td>\n",
       "      <td>ALTW</td>\n",
       "      <td>-233.859120</td>\n",
       "      <td>2023-03-08 22:14:54.353067+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:13:00+00:00</td>\n",
       "      <td>SPC</td>\n",
       "      <td>-10.981597</td>\n",
       "      <td>2023-03-08 22:14:54.353067+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 22:16:00+00:00</td>\n",
       "      <td>SPP NSI Future</td>\n",
       "      <td>-675.000000</td>\n",
       "      <td>2023-03-08 22:14:54.353067+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 22:14:00+00:00</td>\n",
       "      <td>MEC</td>\n",
       "      <td>-456.173798</td>\n",
       "      <td>2023-03-08 22:14:54.353067+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 22:13:00+00:00</td>\n",
       "      <td>ERCOTE</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>2023-03-08 22:14:54.353067+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    gmttime            area          mw  \\\n",
       "0 2023-03-08 22:13:00+00:00            ALTW -233.859120   \n",
       "1 2023-03-08 22:13:00+00:00             SPC  -10.981597   \n",
       "2 2023-03-08 22:16:00+00:00  SPP NSI Future -675.000000   \n",
       "3 2023-03-08 22:14:00+00:00             MEC -456.173798   \n",
       "4 2023-03-08 22:13:00+00:00          ERCOTE   37.599998   \n",
       "\n",
       "                     inserted_time  \n",
       "0 2023-03-08 22:14:54.353067+00:00  \n",
       "1 2023-03-08 22:14:54.353067+00:00  \n",
       "2 2023-03-08 22:14:54.353067+00:00  \n",
       "3 2023-03-08 22:14:54.353067+00:00  \n",
       "4 2023-03-08 22:14:54.353067+00:00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#con.rollback()\n",
    "\n",
    "def update_tie_flows_long(con):\n",
    "    table_name=\"tie_flows_long\"\n",
    "    source_url=\"ftp://pubftp.spp.org/Operational_Data/TIE_FLOW/TieFlows.csv\"\n",
    "    primary_keys=['gmttime', 'area']\n",
    "    \n",
    "    df=pd.read_csv(source_url, \n",
    "                   parse_dates=['GMTTime'], \n",
    "                   infer_datetime_format = True\n",
    "                  )\n",
    "    \n",
    "    df = pd.melt(df, id_vars=['GMTTime'], ignore_index=True).dropna()\n",
    "    \n",
    "    df.rename(columns={'GMTTime':'gmttime', 'variable':'area', 'value':'mw'}, inplace=True)\n",
    "    \n",
    "    standardize_columns(df)  # also adds inserted_time\n",
    "    \n",
    "    # remove future values that will be replaced\n",
    "    #try:\n",
    "    con.execute(text(f\"\"\"\n",
    "      delete from \"{table_name}\" where area = 'SPP NSI Future'\n",
    "      and gmttime > current_timestamp\n",
    "      \"\"\"))\n",
    "    con.commit() \n",
    "    #except: \n",
    "    #    con.rollback()\n",
    "    \n",
    "    pg_insertnew(table_name=table_name, primary_keys=primary_keys, df=df, con=con)\n",
    "    \n",
    "    con.commit()\n",
    "    \n",
    "    return pgsqldf(f\"\"\"select * from {table_name} \n",
    "    where gmttime between current_timestamp - interval '2 minutes' and current_timestamp + interval '2 minutes'\n",
    "    order by random() limit 5\"\"\")\n",
    "\n",
    "\n",
    "#df = update_tie_flows_long(con)\n",
    "#con.commit()\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458da68d",
   "metadata": {},
   "source": [
    "# Real-Time Binding Constraints\n",
    "    https://marketplace.spp.org/file-browser-api/download/rtbm-binding-constraints?path=%2FRTBM-BC-latestInterval.csv\n",
    "    \n",
    " ## TODO\n",
    " DONE: figure out if we are ON or OFF the renaming of columns bandwagon - we are currently ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8ffbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized columns:  ['interval' 'gmtinterval_end' 'constraint_name' 'constraint_type' 'nercid'\n",
      " 'tlr_level' 'state' 'shadow_price' 'monitored_facility'\n",
      " 'contingent_facility' 'inserted_time']\n",
      "pg_insertnew: trying append rtbm_binding_constraints <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmtinterval_end</th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>constraint_type</th>\n",
       "      <th>nercid</th>\n",
       "      <th>tlr_level</th>\n",
       "      <th>state</th>\n",
       "      <th>shadow_price</th>\n",
       "      <th>monitored_facility</th>\n",
       "      <th>contingent_facility</th>\n",
       "      <th>inserted_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 22:15:00+00:00</td>\n",
       "      <td>TMP643_28177</td>\n",
       "      <td>M2M</td>\n",
       "      <td>28177</td>\n",
       "      <td>CME</td>\n",
       "      <td>ACTIVATED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN OAHE - SULLYBT</td>\n",
       "      <td>WAUE:FTTHOMP CHAPELLE:345:2:13</td>\n",
       "      <td>2023-03-08 22:14:56.814235+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-08 22:15:00+00:00</td>\n",
       "      <td>TMP625_28362</td>\n",
       "      <td>FG</td>\n",
       "      <td>28362</td>\n",
       "      <td>CME</td>\n",
       "      <td>ACTIVATED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN JAY_HAWK - FRANKLN5</td>\n",
       "      <td>KCPL:CNTRVILL DAKOTA:161:1:8</td>\n",
       "      <td>2023-03-08 22:14:56.814235+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-08 22:15:00+00:00</td>\n",
       "      <td>TMP500_27577</td>\n",
       "      <td>FG</td>\n",
       "      <td>27577</td>\n",
       "      <td>CME</td>\n",
       "      <td>ACTIVATED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN CAR395 - CARTHAGE</td>\n",
       "      <td>LNCJ366-ASB3491A161EDE</td>\n",
       "      <td>2023-03-08 22:14:56.814235+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-08 22:15:00+00:00</td>\n",
       "      <td>TMP498_28023</td>\n",
       "      <td>FG</td>\n",
       "      <td>28023</td>\n",
       "      <td>CME</td>\n",
       "      <td>ACTIVATED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN SNAKECK - ALIANCE</td>\n",
       "      <td>NPPD:SCOTSBLF VICTRY_H:115:1:5</td>\n",
       "      <td>2023-03-08 22:14:56.814235+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-08 22:15:00+00:00</td>\n",
       "      <td>TMP462_27381</td>\n",
       "      <td>FG</td>\n",
       "      <td>27381</td>\n",
       "      <td>CME</td>\n",
       "      <td>ACTIVATED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN CIMARRON - CKHAL</td>\n",
       "      <td>OKGE:DRAPR1 CIMARRON:345:1:11</td>\n",
       "      <td>2023-03-08 22:14:56.814235+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gmtinterval_end constraint_name constraint_type  nercid tlr_level  \\\n",
       "0 2023-03-08 22:15:00+00:00    TMP643_28177             M2M   28177       CME   \n",
       "1 2023-03-08 22:15:00+00:00    TMP625_28362              FG   28362       CME   \n",
       "2 2023-03-08 22:15:00+00:00    TMP500_27577              FG   27577       CME   \n",
       "3 2023-03-08 22:15:00+00:00    TMP498_28023              FG   28023       CME   \n",
       "4 2023-03-08 22:15:00+00:00    TMP462_27381              FG   27381       CME   \n",
       "\n",
       "       state  shadow_price      monitored_facility  \\\n",
       "0  ACTIVATED           0.0       LN OAHE - SULLYBT   \n",
       "1  ACTIVATED           0.0  LN JAY_HAWK - FRANKLN5   \n",
       "2  ACTIVATED           0.0    LN CAR395 - CARTHAGE   \n",
       "3  ACTIVATED           0.0    LN SNAKECK - ALIANCE   \n",
       "4  ACTIVATED           0.0     LN CIMARRON - CKHAL   \n",
       "\n",
       "              contingent_facility                    inserted_time  \n",
       "0  WAUE:FTTHOMP CHAPELLE:345:2:13 2023-03-08 22:14:56.814235+00:00  \n",
       "1    KCPL:CNTRVILL DAKOTA:161:1:8 2023-03-08 22:14:56.814235+00:00  \n",
       "2          LNCJ366-ASB3491A161EDE 2023-03-08 22:14:56.814235+00:00  \n",
       "3  NPPD:SCOTSBLF VICTRY_H:115:1:5 2023-03-08 22:14:56.814235+00:00  \n",
       "4   OKGE:DRAPR1 CIMARRON:345:1:11 2023-03-08 22:14:56.814235+00:00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_rt_binding(con):\n",
    "    table_name=\"rtbm_binding_constraints\"\n",
    "    source_url=\"https://marketplace.spp.org/file-browser-api/download/rtbm-binding-constraints?path=%2FRTBM-BC-latestInterval.csv\"\n",
    "    primary_keys=['gmtinterval_end', 'constraint_name']\n",
    "    \n",
    "    df=pd.read_csv(source_url, \n",
    "                   parse_dates=['GMTIntervalEnd'], \n",
    "                   infer_datetime_format = True\n",
    "                  )\n",
    "    \n",
    "    #print (df[['GMTIntervalEnd','Constraint Name','Constraint Type','NERCID','Monitored Facility']])\n",
    "\n",
    "    #   in this source file, GMTIntervalEnd does not have a timezone.  Add it: \n",
    "    from datetime import timezone\n",
    "    df['GMTIntervalEnd'] = df['GMTIntervalEnd'].dt.tz_localize(timezone.utc)\n",
    "\n",
    "    # RT binding constraints file has dupes; fix it here\n",
    "    df.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=False)\n",
    "    \n",
    "    \"\"\" df.rename(columns={'Interval':'interval', 'GMTIntervalEnd':'gmt_interval_end', \n",
    "                       'Constraint Name':'constraint_name', 'Constraint Type':'constraint_type',\n",
    "                       'NERCID':'nercid', 'TLR Level':'tlr_level', 'State':'state', 'Shadow Price':'shadow_price',\n",
    "                       'Monitored Facility':'monitored_facility', 'Contingent Facility':'contingent_facility'}, inplace=True)\n",
    "    \"\"\"\n",
    "    standardize_columns(df)\n",
    "    \n",
    "    # interval is now redundant \n",
    "    df.drop(axis='columns', columns=['interval'], inplace=True)\n",
    "\n",
    "#    con.execute(text(\"\"\"delete from rtbm_binding_constraints where \"SPP NSI\" is null\"\"\")); \n",
    "#    con.commit(); \n",
    "      \n",
    "    pg_insertnew(table_name=table_name, primary_keys=primary_keys, df=df, con=con)\n",
    "    \n",
    "    con.commit()\n",
    "    \n",
    "    return pgsqldf(f\"\"\"select * from {table_name} order by gmtinterval_end desc limit 5\"\"\")\n",
    "\n",
    "#update_rt_binding(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0834b56",
   "metadata": {},
   "source": [
    "# DONE.  \n",
    "### Below here is just calling it again to make sure that works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af24d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized columns:  ['gmt_mkt_interval' 'coal_market' 'coal_self' 'diesel_fuel_oil_market'\n",
      " 'diesel_fuel_oil_self' 'hydro_market' 'hydro_self' 'natural_gas_market'\n",
      " 'natural_gas_self' 'nuclear_market' 'nuclear_self' 'solar_market'\n",
      " 'solar_self' 'waste_disposal_services_market'\n",
      " 'waste_disposal_services_self' 'wind_market' 'wind_self'\n",
      " 'waste_heat_market' 'waste_heat_self' 'other_market' 'other_self' 'load'\n",
      " 'inserted_time']\n",
      "pg_insertnew: trying append generation_mix <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading generation_mix_stg\n",
      "pg_insertnew loading generation_mix_stg to generation_mix\n",
      "['GMTTime' 'Value']\n",
      "standardized columns:  ['gmttime' 'value' 'inserted_time']\n",
      "Index(['gmttime', 'value', 'inserted_time'], dtype='object')\n",
      "pg_insertnew: trying append area_control_error <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading area_control_error_stg\n",
      "pg_insertnew loading area_control_error_stg to area_control_error\n",
      "reading https://marketplace.spp.org/file-browser-api/download/stlf-vs-actual?path=%2F2023%2F03%2F08%2F17%2FOP-STLF-202303081610.csv\n",
      "['Interval' 'GMTIntervalEnd' 'STLF' 'Actual']\n",
      "              Interval      GMTIntervalEnd   STLF   Actual\n",
      "0  03/08/2023 16:20:00 2023-03-08 22:20:00  30867      NaN\n",
      "1  03/08/2023 16:15:00 2023-03-08 22:15:00  30840      NaN\n",
      "2  03/08/2023 16:10:00 2023-03-08 22:10:00  30853  30851.0\n",
      "3  03/08/2023 16:05:00 2023-03-08 22:05:00  30794  30842.0\n",
      "standardized columns:  ['interval' 'gmtinterval_end' 'stlf' 'actual' 'inserted_time']\n",
      "pg_insertnew: trying append stlf_vs_actual <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading stlf_vs_actual_stg\n",
      "pg_insertnew loading stlf_vs_actual_stg to stlf_vs_actual\n",
      "update_mltf: found '2023-03-08 17:00:00' already in database\n",
      "standardized columns:  ['gmttime' 'area' 'mw' 'inserted_time']\n",
      "pg_insertnew: trying append tie_flows_long <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading tie_flows_long_stg\n",
      "pg_insertnew loading tie_flows_long_stg to tie_flows_long\n",
      "standardized columns:  ['interval' 'gmtinterval_end' 'constraint_name' 'constraint_type' 'nercid'\n",
      " 'tlr_level' 'state' 'shadow_price' 'monitored_facility'\n",
      " 'contingent_facility' 'inserted_time']\n",
      "pg_insertnew: trying append rtbm_binding_constraints <sqlalchemy.engine.base.Connection object at 0x000001AC81E12020>\n",
      "pg_insertnew append failed, rolling back\n",
      "pg_insertnew making sure table has PK\n",
      "pg_insertnew loading rtbm_binding_constraints_stg\n",
      "pg_insertnew loading rtbm_binding_constraints_stg to rtbm_binding_constraints\n"
     ]
    }
   ],
   "source": [
    "if True: \n",
    "    update_generation_mix(con)\n",
    "    update_ace(con)\n",
    "    update_rtbm_lmp(con)\n",
    "    update_da_lmp(con)\n",
    "    update_stlf(con)\n",
    "    update_mtlf(con)\n",
    "    update_tie_flows_long(con)\n",
    "    update_rt_binding(con)\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "649519a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "while False:\n",
    "    sleep(300)\n",
    "    try: \n",
    "        update_generation_mix(con)\n",
    "        update_ace(con)\n",
    "        update_rtbm_lmp(con)\n",
    "        update_da_lmp(con)\n",
    "        update_stlf(con)\n",
    "        update_mtlf(con)\n",
    "        update_tie_flows(con)\n",
    "        update_rt_binding(con)\n",
    "        con.commit()    \n",
    "    except: \n",
    "        con.rollback()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b88d3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1dc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
